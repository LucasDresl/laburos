{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from binance.client import Client\n",
    "from datetime import datetime \n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense , Dropout , LSTM , CuDNNLSTM\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import tensorflow.compat.v2 as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn import preprocessing\n",
    "from collections import deque\n",
    "import random\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense , Dropout , LSTM , CuDNNLSTM , BatchNormalization\n",
    "# Batchnormalization : so as to dont only normalize your input data , normalize your data layer through layer \n",
    "from tensorflow.keras.callbacks import TensorBoard , ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = 10\n",
    "future_period_predict = 3\n",
    "ratio_to_predict = 'LTCUSDT'\n",
    "bachsize = 64\n",
    "name = f\"{seq}-seq-{future_period_predict}-pred-{ratio_to_predict}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'umXNh30LxCf9EaAVDFX8yBHBXQ8vyyLUbvV0JxY19kAdnrYweqDCCqLaHs3QJmJ9'\n",
    "api_secret = '1so1diWCzjuJyh5dUG4xQXJzDSHAWhhFRpuD5A3aQs5CfgQNEnDEewTmUV2YRZXI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(api_key, api_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cryptos = ['BTCUSDT' , 'LTCUSDT' , 'ETHUSDT']\n",
    "main_df = []\n",
    "\n",
    "for crypto in cryptos:\n",
    "    candles = client.get_klines(symbol=crypto , interval=Client.KLINE_INTERVAL_1DAY)\n",
    "\n",
    "    candles_df = pd.DataFrame(candles)\n",
    "\n",
    "    candles_df_date = candles_df[0]\n",
    "\n",
    "    final_date = []\n",
    "\n",
    "    for time in candles_df_date.unique():\n",
    "        dates = datetime.fromtimestamp(int(time/1000))\n",
    "        final_date.append(dates)\n",
    "\n",
    "    candles_df.pop(0)\n",
    "    candles_df.pop(11)\n",
    "\n",
    "    final_date = pd.DataFrame(final_date)\n",
    "\n",
    "    final_date.columns = ['date']\n",
    "\n",
    "    final_df = candles_df.join(final_date)\n",
    "\n",
    "    final_df.set_index('date' , inplace=True)\n",
    "\n",
    "    final_df.columns = ['open' , 'high' , 'low' ,'close' ,'volume' ,'close_time' ,'asset_value' , 'trades' , 'buy_base_asset_v' , 'buy_quote_asset_v']\n",
    "    final_df = final_df[['close' , 'volume']]\n",
    "    \n",
    "    final_df.rename(columns={'close': f\"{crypto}_close\" , 'volume': f\"{crypto}_volume\"} , inplace=True)\n",
    "    \n",
    "    main_df.append(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(main_df , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTCUSDT_close</th>\n",
       "      <th>BTCUSDT_volume</th>\n",
       "      <th>LTCUSDT_close</th>\n",
       "      <th>LTCUSDT_volume</th>\n",
       "      <th>ETHUSDT_close</th>\n",
       "      <th>ETHUSDT_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-09-09 21:00:00</th>\n",
       "      <td>6312.00000000</td>\n",
       "      <td>32439.45643200</td>\n",
       "      <td>54.34000000</td>\n",
       "      <td>226840.05414000</td>\n",
       "      <td>197.15000000</td>\n",
       "      <td>418489.86663000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-10 21:00:00</th>\n",
       "      <td>6294.91000000</td>\n",
       "      <td>33104.88859000</td>\n",
       "      <td>52.04000000</td>\n",
       "      <td>239830.95074000</td>\n",
       "      <td>185.18000000</td>\n",
       "      <td>476745.79216000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:00:00</th>\n",
       "      <td>6338.62000000</td>\n",
       "      <td>31433.64593900</td>\n",
       "      <td>51.69000000</td>\n",
       "      <td>276375.64336000</td>\n",
       "      <td>183.12000000</td>\n",
       "      <td>504047.79165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-12 21:00:00</th>\n",
       "      <td>6487.38000000</td>\n",
       "      <td>40465.06310700</td>\n",
       "      <td>54.44000000</td>\n",
       "      <td>232884.22924000</td>\n",
       "      <td>210.68000000</td>\n",
       "      <td>739503.34051000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 21:00:00</th>\n",
       "      <td>6476.63000000</td>\n",
       "      <td>37173.33927700</td>\n",
       "      <td>56.24000000</td>\n",
       "      <td>279002.97525000</td>\n",
       "      <td>208.82000000</td>\n",
       "      <td>833945.82573000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     BTCUSDT_close  BTCUSDT_volume LTCUSDT_close  \\\n",
       "date                                                               \n",
       "2018-09-09 21:00:00  6312.00000000  32439.45643200   54.34000000   \n",
       "2018-09-10 21:00:00  6294.91000000  33104.88859000   52.04000000   \n",
       "2018-09-11 21:00:00  6338.62000000  31433.64593900   51.69000000   \n",
       "2018-09-12 21:00:00  6487.38000000  40465.06310700   54.44000000   \n",
       "2018-09-13 21:00:00  6476.63000000  37173.33927700   56.24000000   \n",
       "\n",
       "                      LTCUSDT_volume ETHUSDT_close   ETHUSDT_volume  \n",
       "date                                                                 \n",
       "2018-09-09 21:00:00  226840.05414000  197.15000000  418489.86663000  \n",
       "2018-09-10 21:00:00  239830.95074000  185.18000000  476745.79216000  \n",
       "2018-09-11 21:00:00  276375.64336000  183.12000000  504047.79165000  \n",
       "2018-09-12 21:00:00  232884.22924000  210.68000000  739503.34051000  \n",
       "2018-09-13 21:00:00  279002.97525000  208.82000000  833945.82573000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BTCUSDT_close'] = df['BTCUSDT_close'].astype(str).astype(float)\n",
    "df['BTCUSDT_volume'] = df['BTCUSDT_volume'].astype(str).astype(float)\n",
    "df['LTCUSDT_close'] = df['LTCUSDT_close'].astype(str).astype(float)\n",
    "df['LTCUSDT_volume'] = df['LTCUSDT_volume'].astype(str).astype(float)\n",
    "df['ETHUSDT_close'] = df['ETHUSDT_close'].astype(str).astype(float)\n",
    "df['ETHUSDT_volume'] = df['ETHUSDT_volume'].astype(str).astype(float)\n",
    "#df['BCHUSDT_close'] = df['BCHUSDT_close'].astype(str).astype(float)\n",
    "#df['BCHUSDT_volume'] = df['BCHUSDT_volume'].astype(str).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bitcoin cash have same values\n",
    "#bch = df['BCHUSDT_close']\n",
    "#bch.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build strategy : if the future value expected is bigger than the current price , buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(current , future):\n",
    "    if float(future) > float(current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['future'] = df[f\"{ratio_to_predict}_close\"].shift(-future_period_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Me quedo con las series q tienen datos completas\n",
    "#df = df[df.index > datetime(2019 , 11 , 27)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTCUSDT_close</th>\n",
       "      <th>BTCUSDT_volume</th>\n",
       "      <th>LTCUSDT_close</th>\n",
       "      <th>LTCUSDT_volume</th>\n",
       "      <th>ETHUSDT_close</th>\n",
       "      <th>ETHUSDT_volume</th>\n",
       "      <th>future</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-09-09 21:00:00</th>\n",
       "      <td>6312.00</td>\n",
       "      <td>32439.456432</td>\n",
       "      <td>54.34</td>\n",
       "      <td>226840.05414</td>\n",
       "      <td>197.15</td>\n",
       "      <td>418489.86663</td>\n",
       "      <td>54.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-10 21:00:00</th>\n",
       "      <td>6294.91</td>\n",
       "      <td>33104.888590</td>\n",
       "      <td>52.04</td>\n",
       "      <td>239830.95074</td>\n",
       "      <td>185.18</td>\n",
       "      <td>476745.79216</td>\n",
       "      <td>56.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:00:00</th>\n",
       "      <td>6338.62</td>\n",
       "      <td>31433.645939</td>\n",
       "      <td>51.69</td>\n",
       "      <td>276375.64336</td>\n",
       "      <td>183.12</td>\n",
       "      <td>504047.79165</td>\n",
       "      <td>56.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-12 21:00:00</th>\n",
       "      <td>6487.38</td>\n",
       "      <td>40465.063107</td>\n",
       "      <td>54.44</td>\n",
       "      <td>232884.22924</td>\n",
       "      <td>210.68</td>\n",
       "      <td>739503.34051</td>\n",
       "      <td>56.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 21:00:00</th>\n",
       "      <td>6476.63</td>\n",
       "      <td>37173.339277</td>\n",
       "      <td>56.24</td>\n",
       "      <td>279002.97525</td>\n",
       "      <td>208.82</td>\n",
       "      <td>833945.82573</td>\n",
       "      <td>52.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     BTCUSDT_close  BTCUSDT_volume  LTCUSDT_close  \\\n",
       "date                                                                \n",
       "2018-09-09 21:00:00        6312.00    32439.456432          54.34   \n",
       "2018-09-10 21:00:00        6294.91    33104.888590          52.04   \n",
       "2018-09-11 21:00:00        6338.62    31433.645939          51.69   \n",
       "2018-09-12 21:00:00        6487.38    40465.063107          54.44   \n",
       "2018-09-13 21:00:00        6476.63    37173.339277          56.24   \n",
       "\n",
       "                     LTCUSDT_volume  ETHUSDT_close  ETHUSDT_volume  future  \n",
       "date                                                                        \n",
       "2018-09-09 21:00:00    226840.05414         197.15    418489.86663   54.44  \n",
       "2018-09-10 21:00:00    239830.95074         185.18    476745.79216   56.24  \n",
       "2018-09-11 21:00:00    276375.64336         183.12    504047.79165   56.22  \n",
       "2018-09-12 21:00:00    232884.22924         210.68    739503.34051   56.75  \n",
       "2018-09-13 21:00:00    279002.97525         208.82    833945.82573   52.07  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = list(map(classify ,df[f\"{ratio_to_predict}_close\"] , df['future'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_5pct = round(df.shape[0]*float(0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[:(df.shape[0] - last_5pct)]\n",
    "test = df[(df.shape[0] - last_5pct):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea is to calculate with the previous \"X\" days \n",
    "\n",
    "def preprocess_df(df):\n",
    "    df = df.drop(\"future\", 1)  # don't need this anymore.\n",
    "\n",
    "    for col in df.columns:  # go through all of the columns\n",
    "        if col != \"target\":  # normalize all ... except for the target itself!\n",
    "            df[col] = df[col].pct_change()  # pct change \"normalizes\" the different currencies (each crypto coin has vastly diff values, we're really more interested in the other coin's movements)\n",
    "            df.dropna(inplace=True)  # remove the nas created by pct_change\n",
    "            df[col] = preprocessing.scale(df[col].values)  # scale between 0 and 1.\n",
    "\n",
    "    df.dropna(inplace=True)  # cleanup again... jic.\n",
    "\n",
    "\n",
    "    sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "    prev_days = deque(maxlen=10)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "\n",
    "    for i in df.values:  # iterate over the values\n",
    "        prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "        if len(prev_days) == 10:  # make sure we have 60 sequences!\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
    "\n",
    "    random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "\n",
    "    buys = []  # list that will store our buy sequences and targets\n",
    "    sells = []  # list that will store our sell sequences and targets\n",
    "\n",
    "    for seq, target in sequential_data:  # iterate over the sequential data\n",
    "        if target == 0:  # if it's a \"not buy\"\n",
    "            sells.append([seq, target])  # append to sells list\n",
    "        elif target == 1:  # otherwise if the target is a 1...\n",
    "            buys.append([seq, target])  # it's a buy!\n",
    "\n",
    "    random.shuffle(buys)  # shuffle the buys\n",
    "    random.shuffle(sells)  # shuffle the sells!\n",
    "\n",
    "    lower = min(len(buys), len(sells))  # what's the shorter length?\n",
    "\n",
    "    buys = buys[:lower]  # make sure both lists are only up to the shortest length.\n",
    "    sells = sells[:lower]  # make sure both lists are only up to the shortest length.\n",
    "\n",
    "    sequential_data = buys+sells  # add them together\n",
    "    random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for seq, target in sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "\n",
    "    return np.array(X), y  # return X and y...and make X a numpy array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(475, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x , train_y = preprocess_df(train)\n",
    "test_x , test_y = preprocess_df(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lucas/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/lucas/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 426 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      "426/426 [==============================] - 2s 5ms/sample - loss: 0.9194 - acc: 0.5023 - val_loss: 0.6949 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "426/426 [==============================] - 0s 874us/sample - loss: 0.8034 - acc: 0.5305 - val_loss: 0.6950 - val_acc: 0.5000\n",
      "Epoch 3/10\n",
      "426/426 [==============================] - 0s 703us/sample - loss: 0.7912 - acc: 0.5540 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 4/10\n",
      "426/426 [==============================] - 0s 923us/sample - loss: 0.7490 - acc: 0.5892 - val_loss: 0.6936 - val_acc: 0.5000\n",
      "Epoch 5/10\n",
      "426/426 [==============================] - 0s 841us/sample - loss: 0.6830 - acc: 0.5986 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 6/10\n",
      "426/426 [==============================] - 1s 1ms/sample - loss: 0.7159 - acc: 0.6080 - val_loss: 0.6925 - val_acc: 0.5000\n",
      "Epoch 7/10\n",
      "426/426 [==============================] - 0s 1ms/sample - loss: 0.6497 - acc: 0.6315 - val_loss: 0.6928 - val_acc: 0.5000\n",
      "Epoch 8/10\n",
      "426/426 [==============================] - 0s 864us/sample - loss: 0.6360 - acc: 0.6502 - val_loss: 0.6934 - val_acc: 0.5000\n",
      "Epoch 9/10\n",
      "426/426 [==============================] - 0s 1ms/sample - loss: 0.6246 - acc: 0.6455 - val_loss: 0.6939 - val_acc: 0.5000\n",
      "Epoch 10/10\n",
      "426/426 [==============================] - 0s 1ms/sample - loss: 0.6165 - acc: 0.6808 - val_loss: 0.6944 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3c372ef0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = Sequential()\n",
    "#model.add(LSTM(128 , input_shape=(train_x.shape[:1]) , activation = 'sigmoid' , return_sequences=True))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(BatchNormalization())\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(train_x.shape[1:]),activation='relu' ,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128 , activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32 , activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#tensorboard = TensorBoard(log_dir=\"logs/{}\".format(name))\n",
    "\n",
    "#filepath = \"RNN_Final-{epoch:02d}-{val_acc:.3f}\"  # unique file name that will include the epoch and the validation acc for that epoch\n",
    "#checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')) # saves only the best ones\n",
    "\n",
    "# Train model\n",
    "model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=bachsize,\n",
    "    epochs=10,\n",
    "    validation_data=(test_x, test_y)\n",
    "   # callbacks=[tensorboard, checkpoint],\n",
    ")\n",
    "\n",
    "# Score model\n",
    "#score = model.evaluate(test_x, test_y, verbose=0)\n",
    "#print('Test loss:', score[0])\n",
    "#print('Test accuracy:', score[1])\n",
    "# Save model\n",
    "#model.save(\"models/{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
